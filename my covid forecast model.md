# ToC
# to be classified 
* ideas to create by model
    * using "additive predictors", to incorpoarting different graph structure, 
    * "smoothing" can be used as trade off between complexity and interpretability
    * to account ffor epistemic uncertainty, deep ensemble can be used where each models are trained from scratch with a different random initialization 
# INTRODUCTION
# REFERENCES
# RELATED WORK
# KEY CONTRIBUTION
# CHALLENGES
# TERMINOLOGY
* additive effect
    * when two predictors do not interact, we say that each predictor has an "additive effect' on the response.
        * More formally, a regression model contains additive effects if the response function can be written as a 
         sum of function of the predictor varialbes
* additive predictor 
    * structure additive predictor
        * representa mooth additive effectos of input features and can be reresented in a neural network.
        * it can be represented in neural network term

# STANDARD AND BASELINE
# METHODOLOGY
# RESULT
# FREQUENCY ASK QUESTION 

